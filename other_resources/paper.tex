\documentclass[10pt]{elsarticle}

\usepackage{amsthm,amsmath,amsfonts,amssymb,amscd,mathrsfs}
\usepackage{txfonts}%,pxfonts}
\usepackage{supertabular,soul}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{tikz, graphicx,color,geometry}
 \usepackage{multirow}
 \usetikzlibrary{arrows}
\usepackage[pdftex,
            pdfauthor={Barrett},
            pdftitle={Automorphisms, Equitable Partitions, and Spectral Graph Theory},
            pdfsubject={Equitable Partitions, Spectral Graph Theory},
            pdfkeywords={Equitable Partitions, Spectral Graph Theory}]{hyperref}

\usepackage{bbm} %\mathbb numbers and other symbols
\usepackage{bm} % \boldsymbol
\usepackage{hyperref}
\usepackage{yfonts}
\usepackage{eucal}
\usepackage{overpic}
\usetikzlibrary{calc}
\usepackage{enumitem}

\newcommand{\annotation}[1]{\marginpar{\tiny #1}}
\newcommand{\question}[1]{\medskip\noindent{\bf Question.} #1\medskip}
\newcommand\sHk[1]{{\bf\Large (CHECK: #1)}}
\newcommand{\comment}[1]{}

\makeatletter
\def\ps@pprintTitle{%
\let\@oddhead\@empty
\let\@evenhead\@empty
\let\@oddfoot\@empty
\let\@evenfoot\@oddfoot}
\makeatother

\DeclareMathOperator{\tr}{tr}
\def\big{\bigskip}
\def\m{\medskip}
\def\s{\smallskip}
\def\h{\hfill}
\def\dsp{\displaystyle}

\def \a{\alpha} \def \b{\beta} \def \g{\gamma} \def \d{\delta}
\def \t{\theta} \def \p{\phi} \def \e{\epsilon}
\def \l{\lambda} \def \z{\zeta} \def \o{\omega}

\newcommand{\defital}{\textit}
\newcommand{\ds}{\displaystyle}
\newcommand{\ZZ}{\mathbb Z}
\newcommand{\C}{\mathbb C}
\newcommand{\Q}{\mathbb Q}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\diag}{\text{diag}}
\newcommand{\sL}{\mathscr{L}}
\newcommand{\cT}{\mathcal{T}}
\newcommand{\In}{\text{In}}
\renewcommand{\so}{\mathscr{O}}
%Scripty Things
\renewcommand{\l}{\mathbf{\ell}}
\renewcommand{\r}{{\upsilon}}%%the inclusion of \IC into \cC
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newtheorem{result}{Main Result}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{thm}{Theorem}[section]
\newtheorem{corollary}[thm]{Corollary}
\newtheorem*{thmstar}{Theorem.}
\newtheorem*{propstar}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem*{main2}{Theorem A}
\newtheorem*{main3}{Theorem B}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{sublm}[thm]{Sub-Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{property}{\propertyautorefname}
%\renewcommand{\theproperty}{(\fnsymbol{property})}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{quest}[thm]{Question}
\newtheorem{assumption}[thm]{Convention}
\newtheorem{remark}[thm]{Remark}
\newtheorem{rems}[thm]{Remarks}
\newtheorem{ax}[thm]{Axiom}
\newtheorem{example}[thm]{Example}
%\newtheorem*{example}[thm]{Example}
\newtheorem*{examplestar}{Example}
\theoremstyle{remark}
\newtheorem{notat}{Notation}

%\renewcommand{\thenota}{}
\DeclareMathOperator{\Sing}{Sing}
\DeclareMathOperator{\fix}{Fix}
\providecommand*{\propertyautorefname}{Property}

\setlength{\marginparwidth}{0.8in}
\let\oldmarginpar\marginpar
\renewcommand\marginpar[1]{\oldmarginpar[\raggedleft\footnotesize #1]%
{\raggedright\footnotesize #1}}

\begin{document}
\begin{frontmatter}

\date{\today}

\title{Network Specialization and the Creation of Synchronizing Communities}

\author[adam]{Adam Fidler}
\address[adam]{Department of Mathematics, Brigham Young University, Provo, UT 84602, USA, adam.fidler1@gmail.com }
\author[erik]{Erik Hannesson}
\address[erik]{Department of Mathematics, Brigham Young University, Provo, UT 84602, USA, erikhannesson@gmail.com}
\author[jordan]{Jordan Sellers}
\address[jordan]{Department of Mathematics, Brigham Young University, Provo, UT 84602, USA, jordansellers451@gmail.com }
\author[ethan]{Ethan Walker}
\address[ethan]{Department of Mathematics, Brigham Young University, Provo, UT 84602, USA, ethan.walker830@gmail.com}
\author[ben]{Benjamin Webb}
\address[ben]{Department of Mathematics, Brigham Young University, Provo, UT 84602, USA, bwebb@mathematics.byu.edu}

\begin{abstract}
One of the hallmarks of real networks is their ability to perform increasingly complex tasks as their topology evolves. To explain this, it has been observed that as a network grows certain subsets of the network begin to specialize the function(s) they perform. A recent model of network growth based on this notion of specialization has been able to reproduce some of the most well-known topological features found in real-world networks including right-skewed degree distributions, the small world property, modular as well as hierarchical topology, etc. \textcolor{blue}{Here we describe how...}
\end{abstract}

\begin{keyword}
network specialization, synchronization, equitable partition, communities
\end{keyword}

\end{frontmatter}

\section{Introduction}
Networks studied in the biological, social and technological sciences perform various tasks. How well these tasks are carried out depends both on the network's \emph{topology}, i.e. the network's structure of interactions, as well as the dynamics of the network elements. For instance, in the biological setting neuronal networks are responsible for complicated processes related to cognition and memory, which are based on the network's structure of connections as well as the electrical dynamics of the network neurons \cite{BS09}. The function and performance of social networks such as Facebook and Twitter depend on the social interactions between individuals and on the local/global structure of established relationships. The performance of technological networks such as the internet is based both on the topology of the network's links, e.g. connections between routers, and the router's ability to manage requests.

A major goal of network science is to understand how a network's \emph{topology} and the dynamics of the network's elements effects the network's ability to carry out its function. This goal is complicated by the fact that not only are the network's elements \emph{dynamic}, i.e. have a state that changes over time, but the network's topology also evolves over time. That is, most real-world networks are dynamic in two distinct ways.

The changing state of the network elements is referred to as the \emph{dynamics on} the network. For instance, the dynamics on  the World Wide Web consists of internet traffic, or how many individuals navigate between different web page over time. In a neural network the electrical behavior of the individual neurons is the dynamics on the network. In a distribution network of warehouses and delivery routes, the way in which inventory levels at each warehouse change over time describes the \emph{dynamics on} the network.

In contrast, the structural evolution of a network's topology is referred as the \emph{dynamics of} the network. In a transportation network the topology of the network evolves as new roads are built to increase the number of routes between destinations. In the World Wide Web new links between web pages are added for similar reasons as are new warehouses and delivery routes in distribution networks. In other networks such as social networks the network topology evolves as individuals form new relations, etc...

\section{Network Specialization}

The \emph{topology} of a network, which is the network's structure of interactions, is most often represented by a graph. A \emph{graph} $G=(V,E,\omega)$ is composed of a \emph{vertex set} $V$, an \emph{edge set} $E$, and a function $\omega$ used to weight the edges of the graph. The vertex set $V$ represents the \emph{elements} of the network, while the edges $E$ represent the links or \emph{interactions} between these network elements. The weights of the edges, given by $\omega$, typically give some measure of the \emph{strength} of these interactions. Here we consider weights that are real numbers, which account for the vast majority of weights used in network analysis \cite{Newman10}.

For the graph $G=(V,E,\omega)$ we let $V=\{v_1,\dots,v_n\}$, where $v_i$ represents the $i$th network element. An edge between vertices $v_i$ and $v_j$ can be either directed or undirected depending on the particular network. In the undirected case in which an interaction is reciprocal, e.g. a \emph{friendship} in a social network, one can consider an undirected edge to be two directed edges: one edge pointing from the first to the second element, the other pointing from the second to the first element. We can, therefore, consider any graph to be a directed graph. For a graph $G=(V,E,\omega)$ we let $e_{ij}$ denote the directed edge that begins at $v_j$ and ends at $v_i$. In terms of the network, the edge $e_{ij}$ belongs to the edge set $E$ if the $j$th network element has some direct influence or is linked to the $i$th network element in some way.

The edges $E$ of a graph can also either be \emph{weighted} or \emph{unweighted}. If the edges of a graph $G$ are unweighted we write $G=(V,E)$. However, any unweighted graph can be considered weighted by giving each edge unit weight. The class of graphs we consider, without any loss in generality, in this paper are weighted directed graphs...

To describe the model of network specialization introduced in \cite{BSW18} and its spectral and dynamic consequences we first need to describe the paths and cycles of a graph. A \emph{path}\index{path} $P$ in the graph $G=(V,E,\omega)$ is an ordered sequence of distinct vertices $P=v_1,\dots,v_m$ in $V$ such that $e_{i+1,i}\in E$ for $i=1,\dots,m-1$. If the first and last vertices $v_1$ and $v_m$ are the same then $P$ is a \emph{cycle}\index{cycle}. If it is the case that a cycle contains a single vertex then we call this cycle a \emph{loop}\index{loop}.

Another fundamental concept that we require is the notion of a strongly connected component. A graph $G=(V,E,\omega)$ is \emph{strongly connected} if for any pair of vertices $v_i,v_j\in V$ there is a path from $v_i$ to $v_j$ or, in the trivial case, $G$ consists of a single vertex. A \emph{strongly connected component} of a graph $G$ is a subgraph that is strongly connected and is maximal with respect to this property.

Because we are concerned with evolving the topology of a network in ways that preserve, at least locally, the network's topology we will also need the notion of a graph restriction. For a graph $G=(V,E,\omega)$ and a subset $B\subseteq V$ we let $G|_{B}$ denote the \emph{restriction} of the graph $G$ to the vertex set $B$, which is the subgraph of $G$ on the vertex set $B$ along with any edges of the graph $G$ between the vertices in $B$. We let $\bar{B}$ denote the \emph{complement} of $B$, so that the restriction $G|_{\bar{B}}$ is the graph restricted to the complement of vertices in $B$.

The key to specializing the structure of a graph is to look at the strongly connected components of the restricted graph $G|_{\bar{B}}$. If $C_1,\dots,C_m$ denote these strongly connected components then we need the collection of paths or cycles of these components, which we refer to as \emph{components branches}.

\begin{definition}\label{def:componentbranch} \textbf{(Component Branches)}
For a graph $G=(V,E,\omega)$ and vertex set $B\subseteq V$ let $C_1,\dots,C_m$ be the strongly connected components of $G|_{\bar{B}}$. If there are edges $e_0,e_1,\dots,e_m\in E$ and vertices $v_i,v_j\in B$ such that\\
\indent (i) $e_k$ is an edge from a vertex in $C_k$ to a vertex in $C_{k+1}$ for $k=1,\dots,m-1$;\\
\indent (ii) $e_0$ is an edge from $v_i$ to a vertex in $C_1$; and\\
\indent (iii) $e_m$ is an edge from a vertex in $C_m$ to $v_j$, then we call the ordered set
\[
\beta=\{v_i,e_{0},C_1,e_{1},C_2,\dots,C_m,e_{m},v_{j}\}
\]
a \emph{path of components} in $G$ with respect to $B$. If $v_i=v_j$ then $\beta$ is a \emph{cycle of components}. We call the collection $\mathcal{B}_B(G)$ of these paths and cycles the \emph{component branches} of $G$ with respect to the base set of vertices $B$.
\end{definition}

The sequence of components $C_1,\dots,C_m$ in this definition can be empty in which case $m=0$ and $\beta$ is the trivial path $\beta=\{v_i,v_j\}$ or loop if $v_i=v_j$. It is worth emphasizing that each branch $\beta\in\mathcal{B}_B(G)$ is a subgraph of $G$. Consequently, the edges of $\beta$ inherit the weights they had in $G$ if $G$ is weighted. If $G$ is unweighted then its component branches are likewise unweighted.

Once a graph has been decomposed into its various branches we construct the specialized version of the graph by merging these branches as follows.

\begin{definition} \textbf{(Graph Specialization)}\label{def:exp}
Suppose $G=(V,E,\omega)$ and $B\subseteq V$. Let $\mathcal{S}_B(G)$ be the graph which consists of the component branches $\mathcal{B}_{B}(G)=\{\beta_1,\dots,\beta_{\ell}\}$ in which we \emph{merge}, i.e. identify, each vertex $v_i\in B$ in any branch $\beta_j$ with the same vertex $v_i$ in any other branch $\beta_k$. We refer to the graph  $\mathcal{S}_B(G)$ as the \emph{specialization} of $G$ over the \emph{base} vertex set $B$.
\end{definition}

A specialization of a graph $G$ over a base vertex set $B$ is a two step process. The first step is the construction of the graph's component branches. The second step is the merging of these components into a single graph. We note that, in a component branch $\beta\in\mathcal{B}_B(G)$ only the first and last vertices of $\beta$ belong to the base $B$. The specialized graph $\mathcal{S}_B(G)$ is therefore the collection of branches $\mathcal{B}_B(G)$ in which we identify an endpoint of two branches if they are the same vertex. This is demonstrated in the following example...

Once a graph has been specialized it can again be specialized by choosing a new base of the specialized graph. In this way a network can be sequentially specialized. As a simple example one can randomly choose a fixed percentage of the graph's vertices at each step (see Figure \ref{Fig:-1}). The result is a graph that has many features consistent with real https://www.overleaf.com/6962871568cwfmqwwpgtzk -world networks. For example, it has a right-skewed degree distribution, is disassociative, has the small world property, is sparse, and its topology is both modular and hierarchical (see Example 3.1 in \cite{BSW18}). As one might expect, the resulting sequence of specializations depends very much on the way in which a base is chosen at each step in the specialization process (cf. Example 3.2 and 3.3 in \cite{BSW18}).

\begin{center}
    \textcolor{blue}{It might be better to just introduce Dynamical Networks first then talk about their specialization. What do you think?}
    I agree. I think that an understanding of what dynamical networks are will firstly, help the reader better understand what is being discussed; and secondly, motivate the discussion on specialization. (Ethan)
\end{center}

\section{Specialization of Dynamical Networks}
Sections \ref{sec2} and \ref{sec3} of this paper are primarily concerned with the \emph{dynamics of} a network, i.e. the temporal evolution of the network's structure of interactions, and the spectral consequences of this evolution. This evolution also effects the network's ability to perform its intended function. This function is not only dependent on the network's topology but also on the type of dynamics that emerges from the interactions between the network elements, i.e. the dynamics \emph{on} the network. For instance, power is transferred efficiently in power grids when the grid is synchronized.

In this section our goal is to understand how the dynamics \emph{of} a network can impact the dynamics \emph{on} the network. Specifically, we study under what condition(s) a network can maintain its dynamics as the network's structure evolves via specialization. This ability to maintain functionality even as the network grows is observed in many systems. A prime example is the physiological network of organs within the body, all of which develop over time but maintain specific functions \cite{Plamen2015}.

The dynamics \emph{on} a network with a fixed structure can be formalized as follows.

\begin{definition}\label{def:dn}{\textbf{\emph{(Dynamical Network)}}}
Let $(X_i,d_i)$ be a complete metric space where $X_i\subseteq \mathbb{R}$ and let $(X,d_{max})$ be the complete metric space formed by giving the product space $X=\bigoplus_{i=1}^n X_i$ the metric
\[
d_{max}(\mathbf{x},\mathbf{y}) = \max_i d_i(x_i,y_i) \quad \text{ where } \quad \mathbf{x},\mathbf{y} \in X \quad \text{ and } \quad x_i,y_i \in X_i.
\]
Let $F:X \to X$  be a $C^1(X)$ map with $i^{th}$ component function $F_i:X\to X_i$ given by
\[
F_i = \bigoplus_{j\in I_i}X_j\rightarrow X_i \quad \text{where} \quad I_i\subseteq N=\{1,2,\dots,n\}.
\]
The discrete-time dynamical system $(F,X)$ generated by iterating the function $F$ on $X$ is called a \emph{dynamical network}. If an initial condition $\mathbf{x}^0\in X$ is given, we define the $k^{th}$ \emph{iterate} of $\mathbf{x}^0$ as $\mathbf{x}^k=F^k(\mathbf{x}^0)$, with orbit $\{F^k(\mathbf{x}^0)\}_{k=0}^\infty=\{\mathbf{x}^0,\mathbf{x}^1,\mathbf{x}^2,\hdots\}$ in which $\mathbf{x}^k$ is the state of the network at time $k \ge 0$.
\end{definition}

The component function $F_i$ describes the dynamics of the $i^{th}$ network element that emerges from its interactions with a subset of the other network elements where there is a directed interaction between the $i^{th}$ and $j^{th}$ elements if $j\in I_i$. For the initial condition $\mathbf{x}^0\in X$ the state of the $i^{th}$ element at time $k\ge 0$ is $x^k_i=(F^k(\mathbf{x}^0))_i\in X_i$ where $X_i$ is the state space of the $i^{th}$ element. The state space $X=\bigoplus_{i=1}^n X_i$ is the collective state space of all network elements.

\begin{center}
    \textcolor{blue}{It would probably be better to use the definition in the paper ``Symmetry--and input--cluster Synchronization in Network", i.e. Equation (2). I think we could pretty easily modify what comes next to match that definition.}
\end{center}

\textcolor{blue}{As in:\\
\begin{definition}\label{def:dn2}{\textbf{\emph{(Dynamical Network)}}}
A discrete-time dynamical system can be described by the equation
\[
\mathbf{\p}_i[n+1]=\mathbf{F}(\mathbf{\p}_i[n])+\sigma\sum_j^NA_{ij}\mathbf{H}(\mathbf{\p}_j[n]).\,\, \text{(how do you make Greek letters bold?}
\]
\end{definition}}
Here we consider how growth via specialization can effect the stability of a network. Specifically, we consider the specialization of a class of dynamical networks $(F,X)$ with components of the form
\begin{equation}\label{eq:netclass}
F_i(\mathbf{x})=\sum_{j=1}^n A_{ij}f_{ij}(x_j), \quad \text{for} \quad i\in N=\{1,2,\dots,n\}
\end{equation}
where the matrix $A\in\{0,1\}^{n\times n}$ is a matrix of zeros and ones and each $f_{ij}:X_j\rightarrow\mathbb{R}$ are $C^1(X_j)$ functions with bounded derivatives for all $i,j\in N$. We refer to the graph $G$ with adjacency matrix $A=\mathcal{A}(G)$ in Equation \eqref{eq:netclass} as the \emph{graph of interactions} of $(F,X)$.

It is worth noting that we could absorb the matrix $A$ into the functions $f_{ij}$. However, we use this matrix as a means of specializing the dynamical network $(F,X)$ in a way analogous to the method of specialization described in Section \ref{sec2} for graphs. This is possible as there is a one-to-one relation between a graph $G=(V,E,\omega)$ and its weighted adjacency matrix $\mathcal{A}(G)\in\mathbb{R}^{n\times n}$. Therefore, we can use the notion of a graph specialization to define a matrix specialization.

\begin{definition}\label{def:matspec}\textbf{(Matrix Specialization)}
Let $A\in\mathbb{R}^{n\times n}$ and $B\subseteq N=\{1,2,\dots,n\}$ be a base. Then the \emph{specialization} of $A$ over $B$ is the matrix
\[
\underline{A}=\mathcal{S}_B(A)=\mathcal{A}(\mathcal{S}_B(G))\in\mathbb{R}^{m\times m}
\]
where $A=\mathcal{A}(G)$. Additionally, suppose $G=(V,E,\omega)$ and $\mathcal{S}_B(G)=(\mathcal{V},\mathcal{E},\mu)$. For $M=\{1,2,\dots,m\}$ let $\tau:M\rightarrow N$ where $\tau(i)=j$ if $\nu_i\in\mathcal{V}$ is a copy of $v_j\in V$. We refer to the function $\tau$ as the \emph{origination function} of this specialization.
\end{definition}

Note that we are slightly abusing notation in Definition \ref{def:matspec} by letting the base $B$ be both a subset of $N=\{1,2,\dots,n\}$ and a subset of $V=\{v_1,v_2,\dots,v_n\}$. The idea is that $B\subseteq N$ is a set of indices over which the matrix $A$ is specialized, which in turn is the set that indexes the vertices $B\subseteq V$ over which $G=(V,E,\omega)$ is specialized. Roughly speaking, to specialize the matrix $A\in\mathbb{R}^{n\times n}$ we specialize the associated graph $G$ with adjacency matrix $A$. The adjacency matrix of the resulting specialized graph is the specialization of the matrix $A$. This allows us to specialize dynamical networks as follows.

\begin{definition}\label{def:specdyn}\textbf{(Specializations of Dynamical Networks)}
Suppose $(F,X)$ is a dynamical network given by Equation \eqref{eq:netclass}. If $B\subseteq \{1,2,\dots,n\}$ then the \emph{specialization} of $(F,X)$ over the base $B$ is the dynamical network $(G,Y)$ with components
\[
G_i(\mathbf{y})=\sum_{j=1}^m \underline{A}_{ij}f_{\tau(i)\tau(j)}(y_j), \quad \text{for} \quad i\in M=\{1,2,\dots,m\}
\]
where $\underline{A}=\mathcal{S}_B(A)$, $Y=\bigoplus_{j=1}^m Y_j$ with $Y_j=X_{\tau(j)}$, $y_j=x_{\tau(j)}$, and $\tau:M\rightarrow N$ is the origination function of the specialization.
\end{definition}

\begin{center}
    \textcolor{blue}{Somehow we need to integrate what we need from the paper ``Symmetry--and input--cluster Synchronization in Network", specifically (i) Equaitable Partitions or Clusters, (ii) Automorphisms or Orbital Partitions, (iii) Quotient Graphs and Dynamical Networks, and for a later section (iv) Synchronization.}
\end{center}

\begin{definition}\label{def:inout}\textbf{(Incoming and Outgoing Component Branches)}
For the graph $G=(V,E,\omega)$ and base $B\subseteq V$ let $\beta=\{v_i,e_{0},C_1,e_{1},C_2,\dots,C_m,e_{m},v_{j}\}\in\mathcal{B}_B(G)$. We call the ordered set
\[
In(\beta,C_k)=\{v_i,e_{0},C_1,e_{1},C_2,\dots,C_k\}\subset \beta
\]
the \emph{incoming branch} of $\beta$ up to $C_k$. Similarly, we call the ordered set
\[
Out(\beta,C_k)=\{C_k,e_{k},C_{k+1},\dots,C_m,e_{m},v_{j}\}\subset \beta
\]
the \emph{outgoing branch} in $\beta$ from $C_k$.
\end{definition}

If $Z$ is a strongly connected component of $G|_{\bar{B}}$ then $\ell\geq 0$ copies of it will appear in the graph $\mathcal{S}_B(G)$, which we denote by $\mathcal{C}(Z)=\{Z_1,Z_2,\dots,Z_{\ell}\}$. Here, each $Z_i$ is associated with the component $Z$ in a single branch $\beta_i\in\mathcal{B}_B(G)$. We say $Z_i,Z_j\in\mathcal{C}(Z)$ have the same incoming branch if $In(\beta_i,Z)=In(\beta_j,Z)$ and the same outgoing branch if $Out(\beta_i,Z)=Out(\beta_j,Z)$.

\begin{center}
    \textcolor{blue}{What follows are the definitions and theorems that Ethan put in to the original version he sent out.}
\end{center}


\begin{definition}\label{def:ep}{\textbf{(Equitable Partition)}}
A partition $P$ of a graph $G = (v,e,w)$ is equitable if for any two elements, $C_1$, $C_2$, of the partition, there exists a $k$ such that for all $i\in C_1$ we have
\[
\sum_{j \in C_2} A_{i,j} = k
\]
where $A$ is the adjacency matrix of $G$.
\end{definition}

\begin{definition}\label{def:auto}\textbf{(Automorphism)}
A permutation $\sigma$ of the nodes of a graph $G$, with adjacency matrix $A$, is automorphic if and only if $A_{i,j} = A_{\sigma(i),\sigma(j)}$.
\end{definition}

\begin{definition}\label{def:orbit}{\textbf{\emph{(Orbit and Orbital Partition)}}}
Let $G= {v,e,w}$ be a graph. Let $H \subset Aut(G)$ be a collection of automorphisms of $G$.
The nodes $i$ and $j$ are \emph{similar} under $H$ if there exists an automorphism in $H$ mapping $i$ onto $j$.
The equivalence classes defined by this similarity are the \emph{orbits} of the graph under $H$.
A partition of $G$ formed by a collection of orbits is an \emph{orbital partition} of $G$.
\end{definition}

\begin{definition}\label{def:cut}{\textbf{(Cut)}}
A \emph{cut} of a graph is a partition of the nodes with exactly two elements.
A cut is \emph{equitable} if one of the elements of the cut is an orbit.
A cut is \emph{semi-equitable} if one of the elements of the cut contains an orbit.
\textcolor{blue}{Should we also include a non-equitable cut? (A cut is \emph{non-equitable} if neither element contains an orbit)}
\end{definition}

% \begin{definition}\label{In Branch}
% \end{definition}

\begin{theorem}{\textbf{(Necessary \textcolor{blue}{Sufficient?} Cond for same Part) \\}}
Let $i,j \in \underline{G}_B$. If $\tau(i) = \tau(j)$ and $\tau(\In(i)) = \tau(In(j))$ then $i$ and $j$ are in the same element of the
coarsest equitable partition of $\underline{G}$.
\end{theorem}

\begin{proof}

Let $i$ and $j$ be as given above.
Consider the coarsest equitable partition of $\underline{G}$, $P$. Suppose, by way of contradiction, that there exists some element of $P$, $C$, s.t.
$\sum_{h \in C} A_{i,h} \neq \sum_{h \in C} A_{j,h}$.
This implies without loss of generality that there is some edge $e$ from a vertex $v \in C$ to node $i$, but no such edge to node $j$.
There are two cases:
\begin{itemize}
\item[Case 1] $v \in B$: \\
However by assumption we have that $\tau(in(i)) = \tau(in(j))$ which means that any edge from the base to i must have been copied s.t. there is a corresponding edge from the base to $j$. A contradiction

\item[Case 2] $v \in$ some strongly connected component: \\
However, by the definition of specialization, the exact structure of the SCC that contains $i$ is copied s.t. the structure of the SCC containing $j$ is isomorphic.
Hence, by way of contradiction,$\sum_{h \in C} A_{i,h} = \sum{h \in C} A_{j,h}$
\end{itemize}
\end{proof}

\begin{theorem}(Orbits under Specialization)
Consider a graph $G$ with the base $B$ and the specialization $\underline{G}_B$. Let $O$ be an orbit of $G$ under $H \in Aut(G)$ and let $O \cap B = \emptyset$. Then
\[
\forall i,j \in \underline{G}_B \;\text{with the properties}\; \tau(i) \in O \;\text{and}\; \tau(j) \in O \;\text{and}\;\: \tau(in(i)) = \tau(in(j))
\]
we have that $i$ and $j$ are in the same element of the coarsest equitable partition of $\underline{G}$.
\end{theorem}

\begin{proof}
apply the automorphism before specialization and show that the graphs are isomorphic
\end{proof}

\end{document}
